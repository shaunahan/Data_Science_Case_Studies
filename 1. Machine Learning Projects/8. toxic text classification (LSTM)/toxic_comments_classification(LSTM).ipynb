{
 "cells": [
  
  {
   "cell_type": "markdown",
   "id": "59755226",
   "metadata": {},
   "source": [
    "# Multi-label Classification Modeling using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9a467fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries.\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string, nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdd6e986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n",
      "(153164, 2)\n"
     ]
    }
   ],
   "source": [
    "# import train and test data. \n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_y= pd.read_csv('test_labels.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7d588",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing \n",
    "### Use the same text preprocessing from Step 1 to build a neural network classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b40a4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate   count\n",
       "0      0             0        0       0       0              0  143346\n",
       "1      1             0        0       0       0              0    5666\n",
       "2      1             0        1       0       1              0    3800\n",
       "3      1             0        1       0       0              0    1758\n",
       "4      1             0        0       0       1              0    1215"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding 'no_label' column for comments that do not have a label. \n",
    "label = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train['no_label'] = (train[label].max(axis=1) == 0).astype(int)\n",
    "\n",
    "df_col = train.groupby(label)\\\n",
    "                    .size()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .to_frame('count')\\\n",
    "                    .reset_index()\\\n",
    "                    .head(5)\n",
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e217a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine comments with multiple labels. \n",
    "train[\"multi_label\"] = train.iloc[:,2:8].apply(lambda x: sum(x), axis=1)\n",
    "\n",
    "multi_label_total = {}\n",
    "for value in train[\"multi_label\"].unique():\n",
    "    multi_label_total[value] = train[\"multi_label\"].value_counts()[value]\n",
    "\n",
    "key_list= list(multi_label_total.keys()) \n",
    "value_list = list(multi_label_total.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107f9e39",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6718f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning \n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # replace html characters with \" \"\n",
    "    text = re.sub(\"(http://.*?\\s)|(http://.*)\",'',str(text))\n",
    "    # remove punctuations\n",
    "    text = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]').sub(\" \", text)\n",
    "    # consider only alphabets and numerics\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)  \n",
    "    # replace newline with space\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    # convert to lower case\n",
    "    text = text.lower()\n",
    "    # remove any text starting with User \n",
    "    text = re.sub(\"\\[\\[User.*\",'',str(text))\n",
    "    # remove IP addresses or user IDs\n",
    "    text = re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(text))\n",
    "    # split and join the words\n",
    "    text=' '.join(text.split())\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    # remove any non ascii\n",
    "    text = [word.encode('ascii', 'ignore').decode('ascii') for word in text]\n",
    "    # lematize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a231551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del train['multi_label']\n",
    "    del train['no_label']\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bae28aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer \n",
    "vector = TfidfVectorizer(ngram_range=(1, 1), analyzer='word',\n",
    "                         tokenizer=clean_text, stop_words='english',\n",
    "                         strip_accents='unicode', use_idf=1, min_df=10)\n",
    "X_train = vector.fit_transform(train['comment_text'])\n",
    "X_test = vector.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154a4d9",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "980a2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "col =['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c0aa2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = train['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ba18ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebe83615",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d0f95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tokenizer.texts_to_sequences(sentiment)\n",
    "pad = pad_sequences(seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b553e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment = test['comment_text']\n",
    "test_seq = tokenizer.texts_to_sequences(test_sentiment)\n",
    "test_pad = pad_sequences(test_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1b2b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 100, 128)          2560000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 100)              71600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 306       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,636,956\n",
      "Trainable params: 2,636,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def model_():\n",
    "    inputs = Input(shape=(100, ))\n",
    "    x = Embedding(20000, 128)(inputs)\n",
    "    x = Bidirectional(LSTM(50))(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = model_add()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d1164a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 21:36:53.242709: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-12 21:36:53.474954: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-12 21:36:53.505623: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-12 21:36:53.830158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-12 21:36:53.862004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4488/4488 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 21:41:22.753908: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-12 21:41:22.851664: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-12 21:41:22.859753: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4488/4488 [==============================] - 285s 63ms/step - loss: 0.0632 - accuracy: 0.9637 - val_loss: 0.0509 - val_accuracy: 0.9940\n",
      "Epoch 2/2\n",
      "4488/4488 [==============================] - 273s 61ms/step - loss: 0.0452 - accuracy: 0.9750 - val_loss: 0.0506 - val_accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "model_train = model.fit(pad, y_train, batch_size=32, epochs=2, validation_split=0.1, callbacks=early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43f2ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 21:46:10.252979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-12 21:46:10.330594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-12 21:46:10.352097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 8s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([test_pad], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c881eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = pd.DataFrame(y_test, columns = col)\n",
    "lstm.index = test.id\n",
    "lstm = lstm.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1033abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>6.979026e-02</td>\n",
       "      <td>0.806317</td>\n",
       "      <td>0.020687</td>\n",
       "      <td>0.532997</td>\n",
       "      <td>0.075930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>1.600872e-07</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>1.097890e-06</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.010419</td>\n",
       "      <td>6.665001e-06</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>3.799201e-06</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.744648</td>\n",
       "      <td>3.169456e-03</td>\n",
       "      <td>0.357610</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.180631</td>\n",
       "      <td>0.016579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.025268</td>\n",
       "      <td>1.827607e-05</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>4.509513e-06</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>2.483366e-06</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.876406</td>\n",
       "      <td>2.023619e-02</td>\n",
       "      <td>0.491834</td>\n",
       "      <td>0.022353</td>\n",
       "      <td>0.368440</td>\n",
       "      <td>0.056497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene    threat  \\\n",
       "0       00001cee341fdb12  0.936067  6.979026e-02  0.806317  0.020687   \n",
       "1       0000247867823ef7  0.000502  1.600872e-07  0.000253  0.000003   \n",
       "2       00013b17ad220c46  0.001934  1.097890e-06  0.001028  0.000016   \n",
       "3       00017563c3f7919a  0.010419  6.665001e-06  0.002707  0.000129   \n",
       "4       00017695ad8997eb  0.004132  3.799201e-06  0.001394  0.000060   \n",
       "...                  ...       ...           ...       ...       ...   \n",
       "153159  fffcd0960ee309b5  0.744648  3.169456e-03  0.357610  0.006847   \n",
       "153160  fffd7a9a6eb32c16  0.025268  1.827607e-05  0.005273  0.000359   \n",
       "153161  fffda9e8d6fafa9e  0.005374  4.509513e-06  0.001780  0.000079   \n",
       "153162  fffe8f1340a79fc2  0.007772  2.483366e-06  0.001914  0.000054   \n",
       "153163  ffffce3fb183ee80  0.876406  2.023619e-02  0.491834  0.022353   \n",
       "\n",
       "          insult  identity_hate  \n",
       "0       0.532997       0.075930  \n",
       "1       0.000031       0.000009  \n",
       "2       0.000118       0.000047  \n",
       "3       0.000883       0.000251  \n",
       "4       0.000374       0.000145  \n",
       "...          ...            ...  \n",
       "153159  0.180631       0.016579  \n",
       "153160  0.001990       0.000663  \n",
       "153161  0.000488       0.000170  \n",
       "153162  0.000438       0.000130  \n",
       "153163  0.368440       0.056497  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1eee8",
   "metadata": {},
   "source": [
    "# Conclusion: \n",
    "\n",
    "### Our result shows that LSTM generates 99% accuracy in classifying labels correctly, illustrating that neural networks are more accurate than the traditional machine learning algorithms in classifying labels correctly. \n",
    "\n",
    "###  In the above table, the value in each entry is the predicted probability of column label equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b975b3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
